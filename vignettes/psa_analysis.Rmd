---
title: "Probabilistic Sensitivity Analysis: Analysis"
author: "Fernando Alarid-Escudero, Greg Knowlton, Eva Enns, and the DARTH Team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Probabilistic Sensitivity Analysis: Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)
```

The probabilistic sensitivity analysis (PSA) object is a key part of the `dampack` package. In this vignette, we discuss the goals of a probabilistic sensitivity analysis, how to create the `dampack` PSA object from an existing PSA dataset, and what can be done once the PSA object is created in `dampack`.

`dampack` has additional functionality for generating your own PSA dataset with a user-defined decision model and specified parameter distributions, and those methods are covered in the `psa_generation` vignette. Even if you intend to generate your own PSA dataset using `dampack`, it is recommended that you continue reading this vignette (`psa_analysis`) first.

## Probability Sensitivity Analysis: An Introduction

The purpose of a PSA is to translate model parameter uncertainty into decision uncertainty, reflected as uncertainty as to which strategy is optimal (i.e. has the highest probability of maximizing net monetary benefit). Each uncertain parameter that factors into the decision model is defined by a probability distribution that is independent of the other input parameter distributions. To generate a single PSA sample, a single value is randomly drawn for each parameter from its respective distribution, and those parameter values are plugged into the decision model to calculate the resulting outcomes of interest for each strategy. A large number of samples, say 10,000, are generated in this way, with each iteration using one set of values from the distributions of the parameters and each iteration yielding one set of outcome values. The resulting distribution of outcome values across the PSA samples can translate into decision uncertainty when certain strategies are favored in some samples but not in others.


## PSA in dampack

The PSA object is created using the function `make_psa_obj`. We can see the types of data we need by examining what arguments this function takes. To see more information, you can write `?make_psa_obj` in the R console. As the arguments (and the help text) show, we need the `cost`, `effectiveness`, `strategies` (optional), and `currency` (also optional). 

### Read in data

**explanation of data here?**
There is example data provided with dampack that allows us to illustrate the required structure of each of these parts of a PSA.

```{r}
library(dampack)
data("example_psa")
```


We can see the structure of the object with `str()`:
```{r}
str(example_psa)
```

We can ignore the `wtp` part for now. The other parts of the `example_psa` object are:

- `strategies`: a list of three strategy names
```{r}
example_psa$strategies
```

- `cost`: a data frame of the cost of carrying out each strategy. The columns are the strategies and the
rows are the PSA samples (of which there were 10,000).
```{r}
head(example_psa$cost)
```

- `effectiveness`: a data frame of the effects of carrying out each strategy, with the same structure as `costs`
```{r}
head(example_psa$effectiveness)
```

Note that the columns have names that suggest the strategy and the outcome type in the `example_psa`. When using the `make_psa_obj()` function, it is not actually necessary for the column names in the `cost` and `effectiveness` data.frame inputs to follow this convention; however, it is *critical* that the vector of strategies (`example_psa$strategies`) and the columns of the `cost` and `effectiveness` data.frames be in the same order.

Now, let's make the PSA object and look at its structure:

```{r}
psa_obj <- make_psa_obj(cost = example_psa$cost,
                        effectiveness = example_psa$effectiveness,
                        parameters = example_psa$parameters,
                        strategies = example_psa$strategies,
                        currency = "$")
str(psa_obj)
```

The `psa` object has its own specialized plotting functionality, and the input options for `plot.psa` can be displayed by typing `?plot.psa` in the console. Each dot in the plot represents the the cost and effectiveness of a specific strategy for a single sample of the PSA. The ellipses (shown by default) helps to visualize the clustering of each strategy on the cost-effectiveness plane.

```{r fig.width = 7, fig.height = 5, fig.align = "center"}
plot(psa_obj)
```

When you call `summary()` on a `psa` object, a data.frame is returned that displays the mean cost and mean effect across all of the PSA samples for each strategy. If `calc_sds` is set to `TRUE`, then the standard deviations for these outcomes are displayed as well.

```{r}
psa_sum <- summary(psa_obj, calc_sds = TRUE)
psa_sum
```

For more information about how to use `dampack` to calculate, visualize, and analyze the ICERs for the different strategies compared in a PSA, please see the `basic_cea` vignette.

```{r fig.height = 5, fig.width = 7}
icers <- calculate_icers(cost = psa_sum$meanCost, effect = psa_sum$meanEffect, strategies = psa_sum$Strategy)
plot(icers)
```

##


A strategy's cost-effectiveness is frequently discussed in terms of either net health benefit or net monetary benefit. To calculate a strategy's net health benefit, the cost associated with the strategy is divided by the willingness-to-pay threshold (WTP) and added to the QALYs gained, and to calculate a strategy's net monetary benefit, the number of QALYs gained is multiplied by the WTP threshold and added to the cost. Describing strategies in terms of net health benefit or net monetary benefit is convenient because it allows one to compare the cost-effectiveness of the strategies using a single metric, but these comparisons are sometimes very sensitive to the exact WTP threshold that is used to convert QALYs to currency, or vice versa. The degree to which the choice of willingness-to-pay threshold influences the decision can be analyzed using a cost-effectiveness acceptability curve. The acceptability curves plot the relative frequency or probability that each strategy is cost-effective compared to the alternatives for varying values for society's willingness-to-pay.

The `ceac()` function (`ceac` stands for cost-effectiveness acceptability curve) takes a `psa` object and a numeric vector of willingness to pay thresholds to create a `ceac` object, which is essentially a data.frame with special plotting functionality. The proportion column of the `ceac` object is the proportion of PSA samples in which that particular strategy had the maximum benefit at the corresponding WTP. The `On_Frontier` column indicates whether a strategy was on the cost-effectiveness acceptability frontier at the corresponding WTP. A strategy is on the cost-effectiveness acceptability frontier if it maximizes expected benefit *on average* across all samples of the PSA at the WTP being considered. Note that this designation is fundamentally different than identifying the strategy that has the highest probability of being cost-effective across all samples of the PSA.

```{r}
ceac_obj <- ceac(wtp = example_psa$wtp, psa = psa_obj)
head(ceac_obj)
```

Using the `summary()` function on a `ceac` object yields a data.frame that reports the strategies that are on the cost-effectiveness acceptability frontier along with the ranges of WTP values for which these optimal strategies are most cost-effective.

```{r}
summary(ceac_obj)
```

Plotting a `ceac` object yields a `ggplot2` graph showing the cost-effectiveness acceptability curves for all strategies where the y-axis indicates the probability that each strategy is cost-effective and the x-axis indicates the WTP threshold. By default, the strategies on the cost-effectiveness acceptability frontier are marked with black boxes, and the exact values calculated within the `ceac` object at each provided WTP threshold are marked with points. For more plotting details, see `?plot.ceac`.

```{r}
plot(ceac_obj, frontier = TRUE, points = TRUE)
```

##
Alternatively, the degree to which cost-effectiveness varies with respect to the WTP threshold can be visualized using an expected loss curve (ELC). Expected loss is a quantification of the consequences of choosing a suboptimal strategy in terms of expected foregone benefits. The strategy that minimizes the expected loss at a given WTP value is the optimal decision given current information, and consequently the graph's relationship to the cost-effectiveness acceptability frontier is somewhat more intutive than for CEACs. For an in-depth discussion on the advantages of ELCs in cost-effectiveness analysis, please refer to:

Alarid-Escudero F, Enns EA, Kuntz KM, Michaud TL, Jalal H. "Time Traveling Is Just Too Dangerous" But Some Methods Are Worth Revisiting: The Advantages of Expected Loss Curves Over Cost-Effectiveness Acceptability Curves and Frontier. Value Health. 2019;22(5):611-618.

```{r}
el <- calc_exp_loss(wtp = example_psa$wtp, psa = psa_obj)
head(el)
plot(el, n_x_ticks = 8, n_y_ticks = 6)
```

##

```{r}
o <- owsa(psa_obj)
```


```{r}
plot(o)
```

##

```{r}
owsa_tornado(o)
```

Can filter out strategies that don't change using `min_rel_diff`.

```{r}
owsa_tornado(o, min_rel_diff = 0.05)
```

```{r}
owsa_tornado(o, return = "data")
```

##

```{r, fig.height = 6, fig.width = 8}
owsa_opt_strat(o)
```

```{r}
owsa_opt_strat(o, return = "data")
```

##

```{r}
tw <- twsa(psa_obj, param1 = "pFailChemo", param2 = "muDieCancer")
```

```{r}
plot(tw)
```


